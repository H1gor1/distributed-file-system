# ğŸ“¦ Sistema de Arquivos DistribuÃ­do

Sistema de armazenamento de arquivos distribuÃ­do com replicaÃ§Ã£o automÃ¡tica, utilizando JGroups para comunicaÃ§Ã£o cluster e RMI para comunicaÃ§Ã£o entre camadas.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [O Que o Sistema Faz](#o-que-o-sistema-faz)
- [Arquitetura](#arquitetura)
- [ConfiguraÃ§Ãµes JGroups](#configuraÃ§Ãµes-jgroups)
- [Como Executar](#como-executar)
- [Tecnologias](#tecnologias)

---

## ğŸ¯ VisÃ£o Geral

Este Ã© um sistema de arquivos distribuÃ­do que permite:
- âœ… Upload, download, atualizaÃ§Ã£o e deleÃ§Ã£o de arquivos
- âœ… ReplicaÃ§Ã£o automÃ¡tica em mÃºltiplos servidores
- âœ… AutenticaÃ§Ã£o de usuÃ¡rios com JWT
- âœ… ConsistÃªncia forte com locks distribuÃ­dos
- âœ… Busca de arquivos por nome
- âœ… RecuperaÃ§Ã£o automÃ¡tica de falhas

---

## ğŸš€ O Que o Sistema Faz

O sistema expÃµe uma API REST atravÃ©s do **Gateway HTTP** que permite aos clientes realizarem as seguintes operaÃ§Ãµes:

### ğŸ” AutenticaÃ§Ã£o (`/api/...`)

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/api/register` | POST | Registra novo usuÃ¡rio no sistema |
| `/api/login` | POST | Autentica usuÃ¡rio e retorna token JWT |
| `/api/logout` | POST | Invalida sessÃ£o do usuÃ¡rio |
| `/api/validate` | POST | Valida se um token JWT Ã© vÃ¡lido |

**Funcionalidade**: Gerencia autenticaÃ§Ã£o e sessÃµes de usuÃ¡rios. Os tokens sÃ£o replicados entre os servidores de controle usando JGroups para garantir que qualquer servidor possa validar uma sessÃ£o.

---

### ğŸ“ OperaÃ§Ãµes de Arquivos (`/api/files/...`)

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/api/files/upload` | POST | Faz upload de um arquivo |
| `/api/files/download` | GET | Baixa um arquivo (com lock distribuÃ­do) |
| `/api/files/update` | POST | Atualiza conteÃºdo de um arquivo existente |
| `/api/files/delete` | POST | Remove um arquivo do sistema |
| `/api/files/list` | GET | Lista todos os arquivos do usuÃ¡rio |
| `/api/files/search` | GET | Busca arquivos por nome (todos os usuÃ¡rios) |

**Funcionalidades Especiais**:

- **Upload**: Arquivo Ã© salvo no coordenador do cluster de dados e automaticamente replicado para todos os outros DataServers
- **Download**: Usa lock distribuÃ­do JGroups para garantir que ninguÃ©m estÃ¡ editando o arquivo
- **Update**: MantÃ©m o UUID original, adquire lock, aguarda replicaÃ§Ã£o em TODOS os servidores antes de confirmar sucesso
- **Delete**: Pede confirmaÃ§Ã£o e replica a deleÃ§Ã£o para todo o cluster
- **Search**: Retorna metadados completos (criador, datas, tamanho) de todos os arquivos com aquele nome
- **List**: Lista apenas os arquivos do usuÃ¡rio autenticado

---

## ğŸ—ï¸ Arquitetura

O sistema Ã© composto por **3 camadas distribuÃ­das**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Cliente HTTP                        â”‚
â”‚       (Interface CLI ou Web)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTP REST API
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Gateway HTTP (HttpGateway)             â”‚
â”‚  â€¢ Porta 8080                                    â”‚
â”‚  â€¢ Recebe requisiÃ§Ãµes HTTP dos clientes          â”‚
â”‚  â€¢ Conecta ao control-cluster via JGroups        â”‚
â”‚  â€¢ Faz RPC para ControlServers                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ RPC via JGroups (control-cluster)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Control Cluster (ControlServer)           â”‚
â”‚  â€¢ Gerencia autenticaÃ§Ã£o e sessÃµes               â”‚
â”‚  â€¢ Cluster JGroups: "control-cluster"            â”‚
â”‚  â€¢ Cache replicado de sessÃµes JWT                â”‚
â”‚  â€¢ ComunicaÃ§Ã£o via RPC com DataServers           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ RMI Registry Lookup
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RMI Registry (NameServer)                â”‚
â”‚  â€¢ localhost:1099                                â”‚
â”‚  â€¢ ServiÃ§o: "data-service" â†’ DataServer          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ RMI Remote Call
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Data Cluster (DataServer)               â”‚
â”‚  â€¢ Armazena arquivos com replicaÃ§Ã£o              â”‚
â”‚  â€¢ Cluster JGroups: "data-cluster"               â”‚
â”‚  â€¢ SQLite local + File System                    â”‚
â”‚  â€¢ Coordenador registra-se no RMI Registry       â”‚
â”‚  â€¢ Lock distribuÃ­do para ediÃ§Ãµes/downloads       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ComunicaÃ§Ã£o Entre Camadas

1. **Cliente â†’ Gateway**: HTTP REST
2. **Gateway â†’ ControlServer**: RPC via JGroups (RpcDispatcher)
3. **ControlServer â†’ DataServer**: RMI (Remote Method Invocation)
4. **Dentro de cada cluster**: Mensagens JGroups (replicaÃ§Ã£o, state transfer, locks)

---

## âš™ï¸ ConfiguraÃ§Ãµes JGroups

O sistema utiliza **3 arquivos XML** de configuraÃ§Ã£o do JGroups, cada um otimizado para seu propÃ³sito especÃ­fico.

### ğŸ“„ 1. `fileserver-core/src/main/resources/udp.xml`

**Usado por**: ControlServer (cluster de controle)

**PropÃ³sito**: Gerenciar o cluster de servidores que controlam autenticaÃ§Ã£o e sessÃµes.

```xml
<config xmlns="urn:org:jgroups">
    <UDP />
    <PING />
    <MERGE3 max_interval="30000" min_interval="10000"/>
    <FD_SOCK />
    <FD_ALL timeout="60000" interval="15000" />
    <VERIFY_SUSPECT timeout="5000" />
    <pbcast.NAKACK2 use_mcast_xmit="true" />
    <UNICAST3 />
    <pbcast.STABLE desired_avg_gossip="50000" max_bytes="4M" />
    <pbcast.GMS print_local_addr="true" join_timeout="3000" />
    <pbcast.STATE_TRANSFER />
    <UFC max_credits="2M" min_threshold="0.4" />
    <MFC max_credits="2M" min_threshold="0.4" />
    <FRAG2 frag_size="60K" />
</config>
```

#### ğŸ“ ExplicaÃ§Ã£o dos Protocolos:

| Protocolo | ConfiguraÃ§Ã£o | Por Que Ã‰ NecessÃ¡rio |
|-----------|--------------|----------------------|
| **UDP** | - | Protocolo de transporte base. Usa multicast para descoberta e comunicaÃ§Ã£o eficiente entre membros do cluster. |
| **PING** | - | Descobre novos membros na rede via multicast. Permite que novos ControlServers encontrem o cluster automaticamente. |
| **MERGE3** | `max_interval="30000"`<br>`min_interval="10000"` | Detecta e resolve partiÃ§Ãµes de rede (split-brain). Se dois subclusters se formarem, este protocolo os reÃºne. Tenta merge a cada 10-30 segundos. |
| **FD_SOCK** | - | Detecta falhas via socket TCP. Cada membro mantÃ©m conexÃ£o TCP com vizinhos para detectar crashes rapidamente. |
| **FD_ALL** | `timeout="60000"`<br>`interval="15000"` | Failure detection baseado em heartbeat. Envia pings a cada 15s, considera membro morto apÃ³s 60s sem resposta. |
| **VERIFY_SUSPECT** | `timeout="5000"` | Verifica suspeitas de falha antes de remover membro. Evita falsos positivos (ex: lag temporÃ¡rio de rede). DÃ¡ 5s para membro responder. |
| **NAKACK2** | `use_mcast_xmit="true"` | Garante entrega confiÃ¡vel e ordenada de mensagens via multicast. Retransmite mensagens perdidas (negative acknowledgment). CrÃ­tico para replicaÃ§Ã£o de sessÃµes. |
| **UNICAST3** | - | ComunicaÃ§Ã£o unicast confiÃ¡vel (ponto-a-ponto). Usado para mensagens diretas entre dois membros especÃ­ficos. |
| **STABLE** | `desired_avg_gossip="50000"`<br>`max_bytes="4M"` | Garbage collection de mensagens antigas. Remove mensagens jÃ¡ recebidas por todos apÃ³s ~50s ou 4MB acumulados. Evita memory leak. |
| **GMS** | `print_local_addr="true"`<br>`join_timeout="3000"` | Group Membership Service. Gerencia entrada/saÃ­da de membros, elege coordenador, mantÃ©m view do cluster. Timeout de 3s para join. |
| **STATE_TRANSFER** | - | Transfere estado (cache de sessÃµes) para novos membros. Quando novo ControlServer entra, recebe todas as sessÃµes ativas dos existentes. |
| **UFC** | `max_credits="2M"`<br>`min_threshold="0.4"` | Unicast Flow Control. Previne que remetente sobrecarregue receptor. Bloqueia apÃ³s 2MB nÃ£o-confirmados, libera quando atinge 40% (800KB). |
| **MFC** | `max_credits="2M"`<br>`min_threshold="0.4"` | Multicast Flow Control. Mesmo que UFC mas para mensagens multicast. Protege contra inundaÃ§Ã£o de mensagens broadcast. |
| **FRAG2** | `frag_size="60K"` | Fragmenta mensagens grandes em pedaÃ§os de 60KB. UDP tem limite de ~64KB, este protocolo permite enviar objetos maiores (ex: arquivos). |

**Por Que Este Stack Para ControlServer?**

- âœ… **ReplicaÃ§Ã£o de sessÃµes**: NAKACK2 garante que todas as sessÃµes JWT sejam replicadas
- âœ… **RecuperaÃ§Ã£o de estado**: STATE_TRANSFER permite que novos servidores recebam cache completo
- âœ… **Alta disponibilidade**: FD_SOCK + FD_ALL + VERIFY_SUSPECT detectam falhas rapidamente
- âœ… **ResiliÃªncia a partiÃ§Ãµes**: MERGE3 reÃºne clusters separados
- âœ… **Controle de fluxo**: UFC/MFC evitam sobrecarga de rede
- âŒ **Sem CENTRAL_LOCK**: SessÃµes sÃ£o read-heavy, nÃ£o precisam de locking

---

### ğŸ“„ 2. `fileserver-gateway/src/main/resources/udp.xml`

**Usado por**: HttpGateway (gateway HTTP)

**PropÃ³sito**: Conectar ao cluster de controle para fazer RPC calls aos ControlServers.

```xml
<config xmlns="urn:org:jgroups">
    <UDP />
    <PING />
    <MERGE3 max_interval="30000" min_interval="10000"/>
    <FD_SOCK />
    <FD_ALL timeout="60000" interval="15000" />
    <VERIFY_SUSPECT timeout="5000" />
    <pbcast.NAKACK2 use_mcast_xmit="true" />
    <UNICAST3 />
    <pbcast.STABLE desired_avg_gossip="50000" max_bytes="4M" />
    <pbcast.GMS print_local_addr="true" join_timeout="3000" />
    <pbcast.STATE_TRANSFER />
    <UFC max_credits="2M" min_threshold="0.4" />
    <MFC max_credits="2M" min_threshold="0.4" />
    <FRAG2 frag_size="60K" />
</config>
```

#### ğŸ“ Por Que Ã‰ IdÃªntico ao ControlServer?

**Resposta**: O Gateway **participa do mesmo cluster** (`control-cluster`) mas com papel diferente:

| Aspecto | Gateway | ControlServer |
|---------|---------|---------------|
| **Cluster** | `control-cluster` | `control-cluster` |
| **Recebe estado?** | âŒ NÃ£o | âœ… Sim (cache de sessÃµes) |
| **Envia mensagens?** | âŒ NÃ£o | âœ… Sim (replicaÃ§Ã£o) |
| **Faz RPC?** | âœ… Sim (chama mÃ©todos) | âœ… Sim (responde mÃ©todos) |
| **View do cluster** | âœ… Sim (vÃª todos membros) | âœ… Sim (vÃª todos membros) |

**Funcionalidade do Gateway**:

```java
// Gateway obtÃ©m lista de ControlServers disponÃ­veis
List<Address> getControlServers() {
    return channel.getView().getMembers()
        .stream()
        .filter(addr -> !addr.equals(channel.getAddress()))
        .collect(Collectors.toList());
}

// E faz RPC call balanceado
dispatcher.callRemoteMethod(
    randomControlServer,  // Address obtido da view
    "login",              // MÃ©todo remoto
    new Object[]{username, password},
    ...
);
```

**Por Que Precisa do Stack Completo?**

- âœ… **Descoberta dinÃ¢mica**: PING encontra ControlServers disponÃ­veis
- âœ… **DetecÃ§Ã£o de falhas**: FD_SOCK/FD_ALL sabe quando ControlServer cai
- âœ… **View atualizada**: GMS mantÃ©m lista de servidores vivos para load balancing
- âœ… **RPC confiÃ¡vel**: NAKACK2 + UNICAST3 garantem que chamadas chegam
- âŒ **NÃ£o precisa STATE_TRANSFER**: Gateway nÃ£o armazena estado persistente

---

### ğŸ“„ 3. `fileserver-data/src/main/resources/udp-data.xml`

**Usado por**: DataServer (cluster de dados)

**PropÃ³sito**: Gerenciar cluster de armazenamento com replicaÃ§Ã£o de arquivos e locks distribuÃ­dos.

```xml
<config xmlns="urn:org:jgroups">
    <UDP />
    <PING />
    <MERGE3 max_interval="30000" min_interval="10000"/>
    <FD_SOCK />
    <FD_ALL timeout="60000" interval="15000" />
    <VERIFY_SUSPECT timeout="5000" />
    <pbcast.NAKACK2 use_mcast_xmit="true" />
    <UNICAST3 />
    <pbcast.STABLE desired_avg_gossip="50000" max_bytes="4M" />
    <pbcast.GMS print_local_addr="true" join_timeout="3000" />
    <CENTRAL_LOCK num_backups="1" />
    <pbcast.STATE_TRANSFER />
    <UFC max_credits="2M" min_threshold="0.4" />
    <MFC max_credits="2M" min_threshold="0.4" />
    <FRAG2 frag_size="60K" />
</config>
```

#### ğŸ“ DiferenÃ§as do Control Cluster:

| Protocolo | DiferenÃ§a | Por QuÃª |
|-----------|-----------|---------|
| **CENTRAL_LOCK** | âœ… **PRESENTE** (Ãºnico que tem) | DataServers precisam de **locks distribuÃ­dos** para ediÃ§Ã£o e download de arquivos. Previne condiÃ§Ãµes de corrida. |
| `num_backups="1"` | MantÃ©m 1 backup do lock | Se coordenador de lock cai, backup assume. Garante que lock nÃ£o Ã© perdido. |

#### ğŸ”’ Como CENTRAL_LOCK Ã© Usado:

```java
// No DataServer.editFile()
Lock lock = lockService.getLock(userId + ":" + fileName);
lock.lock();  // Adquire lock distribuÃ­do
try {
    // 1. Atualiza arquivo localmente
    fileRepository.editFile(userId, fileName, newContent);
    
    // 2. Replica para todos os DataServers
    Message msg = new ObjectMessage(null, replication);
    channel.send(msg);
    
    // 3. Aguarda ACKs de todos
    replicationCoordinator.waitForCompletion(opId, 10, TimeUnit.SECONDS);
    
} finally {
    lock.unlock();  // Libera lock
}
```

**CenÃ¡rio de Corrida Prevenido**:

```
Sem Lock:
  T0: User A inicia download de arquivo.txt
  T1: User B inicia ediÃ§Ã£o de arquivo.txt
  T2: Download do A recebe versÃ£o antiga
  T3: EdiÃ§Ã£o do B completa
  âŒ Problema: A baixou versÃ£o inconsistente

Com Lock:
  T0: User A inicia download â†’ lock.lock()
  T1: User B tenta editar â†’ lock.lock() bloqueia
  T2: Download do A completa â†’ lock.unlock()
  T3: Lock do B Ã© adquirido, ediÃ§Ã£o prossegue
  âœ… ConsistÃªncia: A baixou versÃ£o estÃ¡vel
```

#### ğŸ“ ExplicaÃ§Ã£o Completa dos Protocolos DataServer:

| Protocolo | Por Que Ã‰ NecessÃ¡rio No Data Cluster |
|-----------|--------------------------------------|
| **UDP** | ComunicaÃ§Ã£o rÃ¡pida para replicaÃ§Ã£o de arquivos entre DataServers |
| **PING** | Descobre novos DataServers que entram no cluster |
| **MERGE3** | Resolve partiÃ§Ãµes (ex: DataServer-1 e DataServer-2 perderam contato e se reunem) |
| **FD_SOCK + FD_ALL** | Detecta quando DataServer cai para acionar re-replicaÃ§Ã£o |
| **VERIFY_SUSPECT** | Evita remover DataServer por lag de rede temporÃ¡rio |
| **NAKACK2** | **CrÃ­tico**: Garante que replicaÃ§Ã£o de arquivos nÃ£o perde mensagens |
| **UNICAST3** | Usado para ACKs de replicaÃ§Ã£o (ponto-a-ponto) |
| **STABLE** | Limpa mensagens antigas de replicaÃ§Ã£o para economizar memÃ³ria |
| **GMS** | Elege coordenador (que registra no RMI), gerencia membership |
| **CENTRAL_LOCK** | **Exclusivo do DataServer**: Previne ediÃ§Ãµes concorrentes e leitura de arquivo sendo editado |
| **STATE_TRANSFER** | Transfere banco SQLite e arquivos para novo DataServer que entra no cluster |
| **UFC/MFC** | Previne sobrecarga ao replicar arquivos grandes (ex: vÃ­deos de 100MB) |
| **FRAG2** | Permite replicar arquivos maiores que 64KB (limite do UDP) |

**Por Que Este Stack Para DataServer?**

- âœ… **ReplicaÃ§Ã£o confiÃ¡vel**: NAKACK2 + ACKs customizados garantem 100% de replicaÃ§Ã£o
- âœ… **Locks distribuÃ­dos**: CENTRAL_LOCK previne corrupÃ§Ã£o de dados
- âœ… **RecuperaÃ§Ã£o de estado**: Novo DataServer recebe todos os arquivos via STATE_TRANSFER
- âœ… **Failover de coordenador**: Se coordenador RMI cai, GMS elege novo e re-registra
- âœ… **FragmentaÃ§Ã£o**: FRAG2 permite replicar arquivos grandes

---

## ğŸ“Š ComparaÃ§Ã£o dos 3 Arquivos XML

| CaracterÃ­stica | Control (udp.xml) | Gateway (udp.xml) | Data (udp-data.xml) |
|----------------|-------------------|-------------------|---------------------|
| **Cluster** | `control-cluster` | `control-cluster` | `data-cluster` |
| **CENTRAL_LOCK** | âŒ NÃ£o | âŒ NÃ£o | âœ… **Sim** |
| **STATE_TRANSFER** | âœ… Cache de sessÃµes | âŒ NÃ£o usa | âœ… Arquivos + DB |
| **Papel** | Gerencia sessÃµes | Faz RPC calls | Armazena arquivos |
| **ReplicaÃ§Ã£o** | SessÃµes JWT | - | Arquivos binÃ¡rios |
| **Tamanho mensagens** | Pequeno (~1KB) | Pequeno | Grande (atÃ© MBs) |
| **FRAG2 crÃ­tico?** | NÃ£o | NÃ£o | âœ… **Sim** (arquivos grandes) |

---

## ğŸ”„ Fluxo de Dados Completo

### Exemplo: Upload de Arquivo

```
1. Cliente HTTP
   POST /api/files/upload
   Body: { token: "jwt...", fileName: "doc.pdf", content: [bytes] }
   â†“

2. HttpGateway
   â€¢ Recebe requisiÃ§Ã£o HTTP
   â€¢ ObtÃ©m lista de ControlServers via channel.getView()
   â€¢ Faz RPC call via RpcDispatcher:
     clusterClient.uploadFile(token, fileName, content)
   â†“

3. ControlServer (aleatÃ³rio do cluster)
   â€¢ Valida token no cache replicado
   â€¢ Extrai userId do token
   â€¢ Faz lookup do DataService no RMI Registry:
     dataService = registry.lookup("data-service")
   â€¢ Chama mÃ©todo RMI:
     dataService.saveFile(userId, fileName, content)
   â†“

4. DataServer Coordenador
   â€¢ Recebe chamada RMI
   â€¢ Salva arquivo no SQLite + File System
   â€¢ Cria mensagem de replicaÃ§Ã£o: FileReplication(userId, fileName, content, SAVE)
   â€¢ Envia broadcast JGroups:
     channel.send(new ObjectMessage(null, replication))
   â€¢ Aguarda ACKs de todos os DataServers (timeout 10s)
   â†“

5. DataServers RÃ©plicas
   â€¢ Recebem FileReplication via JGroups Receiver
   â€¢ Salvam arquivo no SQLite + File System local
   â€¢ Enviam ACK unicast de volta ao coordenador:
     channel.send(new ObjectMessage(coordenadorAddress, ack))
   â†“

6. Coordenador
   â€¢ Recebe todos os ACKs
   â€¢ Retorna true via RMI â†’ ControlServer â†’ Gateway â†’ Cliente
   â€¢ Cliente recebe: { "success": true, "message": "File uploaded" }
```

### Exemplo: Download com Lock DistribuÃ­do

```
1. Cliente HTTP
   GET /api/files/download?fileName=doc.pdf
   Header: Authorization: Bearer jwt...
   â†“

2. Gateway â†’ ControlServer (via RPC)
   downloadFile(token, fileName)
   â†“

3. ControlServer â†’ DataServer (via RMI)
   dataService.downloadFile(userId, fileName)
   â†“

4. DataServer Coordenador
   Lock lock = lockService.getLock(userId + ":" + fileName);
   lock.lock();  // â† Adquire lock distribuÃ­do JGroups
   try {
       byte[] content = fileRepository.read(userId, fileName);
       return content;  // RMI retorna bytes
   } finally {
       lock.unlock();  // â† Libera lock
   }
   â†“

5. Retorno inverso
   DataServer â†’ ControlServer â†’ Gateway â†’ Cliente
   â€¢ Cliente recebe bytes do arquivo
   â€¢ Durante todo o processo, nenhum outro cliente pode editar o arquivo
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Java 17+
- Maven 3.6+

### 1. Build do Projeto

```bash
mvn clean package
```

### 2. Iniciar DataServers (ordem importante)

```bash
# Terminal 1 - DataServer-1 (cria RMI Registry e vira coordenador)
cd scripts
./start-data-server.sh DataServer-1 localhost 1099

# Terminal 2 - DataServer-2
./start-data-server.sh DataServer-2 localhost 1099

# Terminal 3 - DataServer-3
./start-data-server.sh DataServer-3 localhost 1099
```

### 3. Iniciar ControlServers

```bash
# Terminal 4 - ControlServer-1
cd scripts
./start-control.sh ControlServer-1 localhost 1099

# Terminal 5 - ControlServer-2
./start-control.sh ControlServer-2 localhost 1099
```

### 4. Iniciar Gateway

```bash
# Terminal 6
cd scripts
./start-gateway.sh
```

**Gateway estarÃ¡ disponÃ­vel em**: `http://localhost:8080`

### 5. Iniciar Cliente (opcional)

```bash
# Terminal 7
cd scripts
./start-client.sh
```

---

## ğŸ§ª Testando o Sistema

### Via Cliente CLI

```bash
# Registrar usuÃ¡rio
register joao joao@email.com senha123

# Upload
upload /caminho/para/arquivo.pdf

# Listar
list

# Buscar
search arquivo.pdf

# Download
download arquivo.pdf

# Atualizar
update arquivo.pdf /caminho/para/arquivo-v2.pdf

# Deletar
delete arquivo.pdf
```

### Via cURL

```bash
# Registrar
curl -X POST http://localhost:8080/api/register \
  -H "Content-Type: application/json" \
  -d '{"username":"joao","email":"joao@email.com","password":"senha123"}'

# Login
curl -X POST http://localhost:8080/api/login \
  -H "Content-Type: application/json" \
  -d '{"username":"joao@email.com","password":"senha123"}'

# Upload (exemplo simplificado)
curl -X POST http://localhost:8080/api/files/upload \
  -H "Authorization: Bearer SEU_TOKEN" \
  -F "file=@arquivo.pdf"
```

---

## ğŸ›¡ï¸ Garantias do Sistema

### ConsistÃªncia

- âœ… **ReplicaÃ§Ã£o sÃ­ncrona**: Upload/Update sÃ³ retorna sucesso apÃ³s 100% dos DataServers confirmarem
- âœ… **Locks distribuÃ­dos**: Edit e Download usam CENTRAL_LOCK para prevenir condiÃ§Ãµes de corrida
- âœ… **ACKs obrigatÃ³rios**: Sistema aguarda confirmaÃ§Ã£o de todas as rÃ©plicas antes de confirmar operaÃ§Ã£o

### Disponibilidade

- âœ… **Failover automÃ¡tico**: Se coordenador cai, prÃ³ximo na view assume (GMS)
- âœ… **Descoberta dinÃ¢mica**: Novos servidores sÃ£o descobertos automaticamente (PING)
- âœ… **DetecÃ§Ã£o de falhas**: FD_SOCK + FD_ALL detectam crashes em ~60s
- âœ… **Merge de partiÃ§Ãµes**: MERGE3 reÃºne subclusters separados

### Durabilidade

- âœ… **PersistÃªncia local**: Cada DataServer mantÃ©m SQLite + File System
- âœ… **ReplicaÃ§Ã£o N-vias**: Arquivos existem em todos os DataServers
- âœ… **State Transfer**: Novos servidores recebem estado completo ao entrar

---

## ğŸ› ï¸ Tecnologias

| Tecnologia | VersÃ£o | Uso |
|------------|--------|-----|
| **Java** | 17 | Linguagem principal |
| **JGroups** | 5.3.4 | ComunicaÃ§Ã£o cluster, locks distribuÃ­dos |
| **RMI** | Java Native | ComunicaÃ§Ã£o Control â†’ Data |
| **SQLite** | JDBC | PersistÃªncia de metadata |
| **JWT** | jjwt 0.12.5 | AutenticaÃ§Ã£o stateless |
| **Maven** | 3.6+ | Build e dependÃªncias |

---

## ğŸ“ Estrutura do Projeto

```
distributed-file-system/
â”œâ”€â”€ fileserver-gateway/          # Gateway HTTP (porta 8080)
â”‚   â””â”€â”€ src/main/resources/
â”‚       â””â”€â”€ udp.xml              # Config JGroups para control-cluster
â”œâ”€â”€ fileserver-core/             # ControlServer (autenticaÃ§Ã£o)
â”‚   â””â”€â”€ src/main/resources/
â”‚       â””â”€â”€ udp.xml              # Config JGroups para control-cluster
â”œâ”€â”€ fileserver-data/             # DataServer (armazenamento)
â”‚   â””â”€â”€ src/main/resources/
â”‚       â””â”€â”€ udp-data.xml         # Config JGroups para data-cluster
â”œâ”€â”€ fileserver-client/           # Cliente CLI
â”œâ”€â”€ fileserver-common/           # Modelos e interfaces compartilhadas
â”œâ”€â”€ scripts/                     # Scripts de inicializaÃ§Ã£o
â”œâ”€â”€ DataServer-1/                # Dados do DataServer-1
â”œâ”€â”€ DataServer-2/                # Dados do DataServer-2
â”œâ”€â”€ DataServer-3/                # Dados do DataServer-3
â””â”€â”€ downloads/                   # Arquivos baixados pelo cliente
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Arquitetura RMI](README-RMI-ARCHITECTURE.md) - Detalhes sobre RMI Registry e comunicaÃ§Ã£o entre camadas
- [RPC com JGroups](README-RPC.md) - Como funciona RpcDispatcher
- [Funcionalidades](FUNCIONALIDADES.md) - Lista completa de features implementadas
- [Quick Start](QUICKSTART.md) - Guia rÃ¡pido de uso

---

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

---

## ğŸ“ LicenÃ§a

Este projeto Ã© distribuÃ­do sob a licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.

---

## ğŸ‘¥ Autores

- **Higor Lino** - Desenvolvimento inicial

---

## ğŸ“ Contexto AcadÃªmico

Este sistema foi desenvolvido como projeto da disciplina de Sistemas DistribuÃ­dos do IFMG, demonstrando conceitos de:

- ComunicaÃ§Ã£o em cluster (JGroups)
- ReplicaÃ§Ã£o de dados
- Locks distribuÃ­dos
- RPC e RMI
- TolerÃ¢ncia a falhas
- ConsistÃªncia forte
- State transfer
- Failure detection
